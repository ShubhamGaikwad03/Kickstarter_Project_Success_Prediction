{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820f8802",
   "metadata": {
    "id": "820f8802"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nJvodTgxMR5B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJvodTgxMR5B",
    "outputId": "601b4293-ae26-4859-a554-f20e6a83fc90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# uncomment this lines to use the code in google collab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65cdcafe",
   "metadata": {
    "id": "65cdcafe"
   },
   "outputs": [],
   "source": [
    "# Load the Kickstarter dataset\n",
    "#df = pd.read_csv('/content/drive/MyDrive/257 Project/kickstarter_data_full.csv'). way to access data from google collab\n",
    "\n",
    "filename = 'kickstarter_data_full.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df.drop(columns=['Unnamed: 0', 'id','name', 'blurb','photo', 'slug', 'disable_communication', \n",
    "                 'currency_symbol', 'currency_trailing_code', 'creator', \n",
    "                 'location', 'category', 'profile', 'urls', 'source_url', \n",
    "                 'friends', 'is_starred', 'is_backing', 'permissions'], \n",
    "        inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4471b9ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4471b9ce",
    "outputId": "10b6224d-cfb7-4d7c-d075-36c55a1b1e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20632 entries, 0 to 20631\n",
      "Data columns (total 49 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   goal                         20632 non-null  float64\n",
      " 1   pledged                      20632 non-null  float64\n",
      " 2   state                        20632 non-null  object \n",
      " 3   country                      20632 non-null  object \n",
      " 4   currency                     20632 non-null  object \n",
      " 5   deadline                     20632 non-null  object \n",
      " 6   state_changed_at             20632 non-null  object \n",
      " 7   created_at                   20632 non-null  object \n",
      " 8   launched_at                  20632 non-null  object \n",
      " 9   staff_pick                   20632 non-null  bool   \n",
      " 10  backers_count                20632 non-null  int64  \n",
      " 11  static_usd_rate              20632 non-null  float64\n",
      " 12  usd_pledged                  20632 non-null  float64\n",
      " 13  spotlight                    20632 non-null  bool   \n",
      " 14  name_len                     20627 non-null  float64\n",
      " 15  name_len_clean               20627 non-null  float64\n",
      " 16  blurb_len                    20627 non-null  float64\n",
      " 17  blurb_len_clean              20627 non-null  float64\n",
      " 18  deadline_weekday             20632 non-null  object \n",
      " 19  state_changed_at_weekday     20632 non-null  object \n",
      " 20  created_at_weekday           20632 non-null  object \n",
      " 21  launched_at_weekday          20632 non-null  object \n",
      " 22  deadline_month               20632 non-null  int64  \n",
      " 23  deadline_day                 20632 non-null  int64  \n",
      " 24  deadline_yr                  20632 non-null  int64  \n",
      " 25  deadline_hr                  20632 non-null  int64  \n",
      " 26  state_changed_at_month       20632 non-null  int64  \n",
      " 27  state_changed_at_day         20632 non-null  int64  \n",
      " 28  state_changed_at_yr          20632 non-null  int64  \n",
      " 29  state_changed_at_hr          20632 non-null  int64  \n",
      " 30  created_at_month             20632 non-null  int64  \n",
      " 31  created_at_day               20632 non-null  int64  \n",
      " 32  created_at_yr                20632 non-null  int64  \n",
      " 33  created_at_hr                20632 non-null  int64  \n",
      " 34  launched_at_month            20632 non-null  int64  \n",
      " 35  launched_at_day              20632 non-null  int64  \n",
      " 36  launched_at_yr               20632 non-null  int64  \n",
      " 37  launched_at_hr               20632 non-null  int64  \n",
      " 38  create_to_launch             20632 non-null  object \n",
      " 39  launch_to_deadline           20632 non-null  object \n",
      " 40  launch_to_state_change       20632 non-null  object \n",
      " 41  create_to_launch_days        20632 non-null  int64  \n",
      " 42  launch_to_deadline_days      20632 non-null  int64  \n",
      " 43  launch_to_state_change_days  20632 non-null  int64  \n",
      " 44  SuccessfulBool               20632 non-null  int64  \n",
      " 45  USorGB                       20632 non-null  int64  \n",
      " 46  TOPCOUNTRY                   20632 non-null  int64  \n",
      " 47  LaunchedTuesday              20632 non-null  int64  \n",
      " 48  DeadlineWeekend              20632 non-null  int64  \n",
      "dtypes: bool(2), float64(8), int64(25), object(14)\n",
      "memory usage: 7.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a0708b",
   "metadata": {
    "id": "c1a0708b"
   },
   "outputs": [],
   "source": [
    "# find value counts for all columns in the DataFrame\n",
    "# for col in df.columns:\n",
    "#     print(f\"{col}:\")\n",
    "#     print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c27f93",
   "metadata": {
    "id": "18c27f93"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d814c4d",
   "metadata": {
    "id": "3d814c4d"
   },
   "source": [
    "## Updating the Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f17ba03a",
   "metadata": {
    "id": "f17ba03a"
   },
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "    elif df[column].dtype.name == 'category':\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "    else:\n",
    "        df[column].fillna(df[column].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274a828",
   "metadata": {
    "id": "8274a828"
   },
   "source": [
    "## Converting all Data Types to Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58fbecc0",
   "metadata": {
    "id": "58fbecc0"
   },
   "outputs": [],
   "source": [
    "\n",
    "df['staff_pick'] = df['staff_pick'].astype(int)\n",
    "df['spotlight'] = df['spotlight'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd880189",
   "metadata": {
    "id": "cd880189"
   },
   "outputs": [],
   "source": [
    "# Convert categorical features to numerical using one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['state', 'country', 'currency'])\n",
    "df = pd.get_dummies(df, columns=['deadline_weekday', 'state_changed_at_weekday', 'created_at_weekday', 'launched_at_weekday'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0842e29",
   "metadata": {
    "id": "d0842e29"
   },
   "outputs": [],
   "source": [
    "# Convert categorical features to numerical using one-hot encoding\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "469e75bb",
   "metadata": {
    "id": "469e75bb"
   },
   "outputs": [],
   "source": [
    "df['deadline'] = pd.to_datetime(df['deadline']).astype('int64') * 1e-9\n",
    "df['state_changed_at'] = pd.to_datetime(df['state_changed_at']).astype('int64') * 1e-9\n",
    "df['created_at'] = pd.to_datetime(df['created_at']).astype('int64') * 1e-9\n",
    "df['launched_at'] = pd.to_datetime(df['launched_at']).astype('int64') * 1e-9\n",
    "\n",
    "df['deadline_yr'] = pd.to_datetime(df['deadline']).dt.year.astype(float)\n",
    "df['deadline_month'] = pd.to_datetime(df['deadline']).dt.month.astype(float)\n",
    "df['deadline_day'] = pd.to_datetime(df['deadline']).dt.day.astype(float)\n",
    "df['deadline_hr'] = pd.to_datetime(df['deadline']).dt.hour.astype(float)\n",
    "\n",
    "df['state_changed_at_yr'] = pd.to_datetime(df['state_changed_at']).dt.year.astype(float)\n",
    "df['state_changed_at_month'] = pd.to_datetime(df['state_changed_at']).dt.month.astype(float)\n",
    "df['state_changed_at_day'] = pd.to_datetime(df['state_changed_at']).dt.day.astype(float)\n",
    "df['state_changed_at_hr'] = pd.to_datetime(df['state_changed_at']).dt.hour.astype(float)\n",
    "\n",
    "df['created_at_yr'] = pd.to_datetime(df['created_at']).dt.year.astype(float)\n",
    "df['created_at_month'] = pd.to_datetime(df['created_at']).dt.month.astype(float)\n",
    "df['created_at_day'] = pd.to_datetime(df['created_at']).dt.day.astype(float)\n",
    "df['created_at_hr'] = pd.to_datetime(df['created_at']).dt.hour.astype(float)\n",
    "\n",
    "df['launched_at_yr'] = pd.to_datetime(df['launched_at']).dt.year.astype(float)\n",
    "df['launched_at_month'] = pd.to_datetime(df['launched_at']).dt.month.astype(float)\n",
    "df['launched_at_day'] = pd.to_datetime(df['launched_at']).dt.day.astype(float)\n",
    "df['launched_at_hr'] = pd.to_datetime(df['launched_at']).dt.hour.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db983663",
   "metadata": {
    "id": "db983663"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5330d34",
   "metadata": {
    "id": "f5330d34"
   },
   "outputs": [],
   "source": [
    "df['create_to_launch'] = pd.to_timedelta(df['create_to_launch']).dt.total_seconds() / 86400.0\n",
    "df['launch_to_deadline'] = pd.to_timedelta(df['launch_to_deadline']).dt.total_seconds() / 86400.0\n",
    "df['launch_to_state_change'] = pd.to_timedelta(df['launch_to_state_change']).dt.total_seconds() / 86400.0\n",
    "\n",
    "df['create_to_launch_days'] = df['create_to_launch_days'].astype(float)\n",
    "df['launch_to_deadline_days'] = df['launch_to_deadline_days'].astype(float)\n",
    "df['launch_to_state_change_days'] = df['launch_to_state_change_days'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74f31eb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74f31eb8",
    "outputId": "f0d52f45-5aa0-4bae-ea5e-0f404c66cb7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20632 entries, 0 to 20631\n",
      "Columns: 109 entries, goal to launched_at_weekday_Wednesday\n",
      "dtypes: float64(34), int64(8), uint8(67)\n",
      "memory usage: 7.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1962a22",
   "metadata": {
    "id": "f1962a22"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "295cb9eb",
   "metadata": {
    "id": "295cb9eb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b44158e",
   "metadata": {
    "id": "9b44158e"
   },
   "outputs": [],
   "source": [
    "# Set output variable\n",
    "y_imbalanced = df[\"SuccessfulBool\"]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "X_imbalanced = df.drop([\"deadline\", \"state_changed_at\", \"created_at\", \"launched_at\", \"name_len_clean\", \"blurb_len_clean\", \"SuccessfulBool\"], axis=1)\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imbalanced, y_imbalanced, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ymDpecaTnxE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ymDpecaTnxE",
    "outputId": "3028bff1-11fc-40fb-d9f8-f8a91540bd5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data distribution:\n",
      "0    70.831718\n",
      "1    29.168282\n",
      "Name: SuccessfulBool, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate class distribution\n",
    "class_distribution = y_imbalanced.value_counts(normalize=True) * 100\n",
    "\n",
    "# Print class distribution\n",
    "print(\"Data distribution:\")\n",
    "print(class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "RLGrISPfMp33",
   "metadata": {
    "id": "RLGrISPfMp33"
   },
   "outputs": [],
   "source": [
    "# Apply undersampling to the majority class\n",
    "undersampler = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
    "X_train_undersampled, y_train_undersampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Apply SMOTE to the minority class\n",
    "smote = SMOTE(sampling_strategy=1.0, random_state=42)\n",
    "X, y = smote.fit_resample(X_train_undersampled, y_train_undersampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0c50d8c",
   "metadata": {
    "id": "e0c50d8c",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hIIhs_KcMonJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIIhs_KcMonJ",
    "outputId": "21f0496e-4e73-4f4d-a38e-27e55e2e5baa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "20627    0\n",
       "20628    0\n",
       "20629    0\n",
       "20630    0\n",
       "20631    0\n",
       "Name: SuccessfulBool, Length: 20632, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1ef34bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1ef34bd",
    "outputId": "c954fefe-8ed8-45c9-e50b-79b292bd6baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data distribution:\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: SuccessfulBool, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate class distribution\n",
    "class_distribution = y.value_counts(normalize=True) * 100\n",
    "\n",
    "# Print class distribution\n",
    "print(\"Data distribution:\")\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9d1f612",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9d1f612",
    "outputId": "57a2e9e2-7e58-43a6-e19a-7252d61887a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "goal\n",
      "pledged\n",
      "staff_pick\n",
      "backers_count\n",
      "static_usd_rate\n",
      "usd_pledged\n",
      "spotlight\n",
      "name_len\n",
      "blurb_len\n",
      "deadline_month\n",
      "deadline_day\n",
      "deadline_yr\n",
      "deadline_hr\n",
      "state_changed_at_month\n",
      "state_changed_at_day\n",
      "state_changed_at_yr\n",
      "state_changed_at_hr\n",
      "created_at_month\n",
      "created_at_day\n",
      "created_at_yr\n",
      "created_at_hr\n",
      "launched_at_month\n",
      "launched_at_day\n",
      "launched_at_yr\n",
      "launched_at_hr\n",
      "create_to_launch\n",
      "launch_to_deadline\n",
      "launch_to_state_change\n",
      "create_to_launch_days\n",
      "launch_to_deadline_days\n",
      "launch_to_state_change_days\n",
      "USorGB\n",
      "TOPCOUNTRY\n",
      "LaunchedTuesday\n",
      "DeadlineWeekend\n",
      "state_canceled\n",
      "state_failed\n",
      "state_live\n",
      "state_successful\n",
      "state_suspended\n",
      "country_AT\n",
      "country_AU\n",
      "country_BE\n",
      "country_CA\n",
      "country_CH\n",
      "country_DE\n",
      "country_DK\n",
      "country_ES\n",
      "country_FR\n",
      "country_GB\n",
      "country_HK\n",
      "country_IE\n",
      "country_IT\n",
      "country_LU\n",
      "country_MX\n",
      "country_NL\n",
      "country_NO\n",
      "country_NZ\n",
      "country_SE\n",
      "country_SG\n",
      "country_US\n",
      "currency_AUD\n",
      "currency_CAD\n",
      "currency_CHF\n",
      "currency_DKK\n",
      "currency_EUR\n",
      "currency_GBP\n",
      "currency_HKD\n",
      "currency_MXN\n",
      "currency_NOK\n",
      "currency_NZD\n",
      "currency_SEK\n",
      "currency_SGD\n",
      "currency_USD\n",
      "deadline_weekday_Friday\n",
      "deadline_weekday_Monday\n",
      "deadline_weekday_Saturday\n",
      "deadline_weekday_Sunday\n",
      "deadline_weekday_Thursday\n",
      "deadline_weekday_Tuesday\n",
      "deadline_weekday_Wednesday\n",
      "state_changed_at_weekday_Friday\n",
      "state_changed_at_weekday_Monday\n",
      "state_changed_at_weekday_Saturday\n",
      "state_changed_at_weekday_Sunday\n",
      "state_changed_at_weekday_Thursday\n",
      "state_changed_at_weekday_Tuesday\n",
      "state_changed_at_weekday_Wednesday\n",
      "created_at_weekday_Friday\n",
      "created_at_weekday_Monday\n",
      "created_at_weekday_Saturday\n",
      "created_at_weekday_Sunday\n",
      "created_at_weekday_Thursday\n",
      "created_at_weekday_Tuesday\n",
      "created_at_weekday_Wednesday\n",
      "launched_at_weekday_Friday\n",
      "launched_at_weekday_Monday\n",
      "launched_at_weekday_Saturday\n",
      "launched_at_weekday_Sunday\n",
      "launched_at_weekday_Thursday\n",
      "launched_at_weekday_Tuesday\n",
      "launched_at_weekday_Wednesday\n"
     ]
    }
   ],
   "source": [
    "# Assuming the DataFrame is named 'df'\n",
    "column_names = X.columns.tolist()\n",
    "\n",
    "print(\"Column names:\")\n",
    "for column in column_names:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a9e39",
   "metadata": {
    "id": "476a9e39"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5340bb4",
   "metadata": {
    "id": "f5340bb4"
   },
   "outputs": [],
   "source": [
    "#selected_features\n",
    "X_numpy = X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d27cd",
   "metadata": {
    "id": "e27d27cd"
   },
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "524ddcb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "524ddcb0",
    "outputId": "5c91325d-843a-498f-a878-45c053823c60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "Precision: 100.00%\n",
      "Recall: 100.00%\n",
      "F1 score: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the AdaBoost classifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier()\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Create lists to store the evaluation metric values for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "for train_index, test_index in skf.split(X_numpy, y):\n",
    "    X_train, X_test = X_numpy[train_index], X_numpy[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the logistic regression model\n",
    "    ada_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = ada_clf.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Append evaluation metric values to the respective lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate the mean of the evaluation metric values across all folds\n",
    "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy: {:.2f}%\".format(mean_accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(mean_precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(mean_recall * 100))\n",
    "print(\"F1 score: {:.2f}%\".format(mean_f1 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96a92bc",
   "metadata": {
    "id": "a96a92bc"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f428f1d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f428f1d5",
    "outputId": "22ff86a0-5363-46eb-f531-8e1d6d670eb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.94634019 0.94503777 0.94762897 0.94971339 0.95909328]\n",
      "Mean cross-validation score: 0.9495627213151115\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "log_reg_clf = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the Logistic Regression classifier\n",
    "log_reg_clf.fit(X_train, y_train)\n",
    "\n",
    "k = 5\n",
    "# Create a StratifiedKFold object\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(log_reg_clf, X, y, cv=kf)\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Mean cross-validation score:', np.mean(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "414004c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "414004c5",
    "outputId": "f0f445ad-48b1-4024-ad0c-05a8bf487905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.96%\n",
      "Precision: 94.08%\n",
      "Recall: 95.96%\n",
      "F1 score: 95.01%\n"
     ]
    }
   ],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Create lists to store the evaluation metric values for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "for train_index, test_index in skf.split(X_numpy, y):\n",
    "    X_train, X_test = X_numpy[train_index], X_numpy[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the logistic regression model\n",
    "    log_reg_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = log_reg_clf.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Append evaluation metric values to the respective lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate the mean of the evaluation metric values across all folds\n",
    "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy: {:.2f}%\".format(mean_accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(mean_precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(mean_recall * 100))\n",
    "print(\"F1 score: {:.2f}%\".format(mean_f1 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b34481",
   "metadata": {
    "id": "36b34481"
   },
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3562ef8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3562ef8d",
    "outputId": "a92bb1fc-0a37-4f45-fae3-c459568aed07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.99192498 0.99036207 0.98801459 0.9890568  0.99088067]\n",
      "Mean cross-validation score: 0.9900478224568046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the K-NN classifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "# Train the K-NN classifier\n",
    "k = 5\n",
    "# Create a StratifiedKFold object\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(knn_clf, X, y, cv=kf)\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Mean cross-validation score:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff8563bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff8563bf",
    "outputId": "3c56ad72-c9c4-4e7b-a3d0-64e33d194ce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.00%\n",
      "Precision: 98.12%\n",
      "Recall: 99.93%\n",
      "F1 score: 99.01%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Create lists to store the evaluation metric values for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "for train_index, test_index in skf.split(X_numpy, y):\n",
    "    X_train, X_test = X_numpy[train_index], X_numpy[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the logistic regression model\n",
    "    knn_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = knn_clf.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Append evaluation metric values to the respective lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate the mean of the evaluation metric values across all folds\n",
    "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "# Print the final evaluation metric values\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy: {:.2f}%\".format(mean_accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(mean_precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(mean_recall * 100))\n",
    "print(\"F1 score: {:.2f}%\".format(mean_f1 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b885ca",
   "metadata": {
    "id": "27b885ca"
   },
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d5d40e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d5d40e9",
    "outputId": "5c48db3a-ae6e-419d-e7af-9c0df75b7216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Mean cross-validation score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the Decision Tree classifier\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Train the K-NN classifier\n",
    "k = 5\n",
    "# Create a StratifiedKFold object\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(tree_clf, X, y, cv=kf)\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Mean cross-validation score:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1d1c32e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1d1c32e",
    "outputId": "34801cc9-5536-4afe-fb7f-60786b618a8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "Precision: 100.00%\n",
      "Recall: 100.00%\n",
      "F1 score: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Create lists to store the evaluation metric values for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "for train_index, test_index in skf.split(X_numpy, y):\n",
    "    X_train, X_test = X_numpy[train_index], X_numpy[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the logistic regression model\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = tree_clf.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Append evaluation metric values to the respective lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate the mean of the evaluation metric values across all folds\n",
    "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy: {:.2f}%\".format(mean_accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(mean_precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(mean_recall * 100))\n",
    "print(\"F1 score: {:.2f}%\".format(mean_f1 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75c74a",
   "metadata": {
    "id": "ce75c74a"
   },
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "565abedf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "565abedf",
    "outputId": "7d856e97-bb77-41d6-8e9e-da598a50efb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Mean cross-validation score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "forest_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Train the K-NN classifier\n",
    "k = 5\n",
    "# Create a StratifiedKFold object\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(forest_clf, X, y, cv=kf)\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Mean cross-validation score:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37997d8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37997d8f",
    "outputId": "575c6718-a4b6-426f-f73f-dfe8e032d803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "Precision: 100.00%\n",
      "Recall: 100.00%\n",
      "F1 score: 100.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Create lists to store the evaluation metric values for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "for train_index, test_index in skf.split(X_numpy, y):\n",
    "    X_train, X_test = X_numpy[train_index], X_numpy[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the logistic regression model\n",
    "    forest_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = forest_clf.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Append evaluation metric values to the respective lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate the mean of the evaluation metric values across all folds\n",
    "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy: {:.2f}%\".format(mean_accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(mean_precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(mean_recall * 100))\n",
    "print(\"F1 score: {:.2f}%\".format(mean_f1 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecba880",
   "metadata": {
    "id": "9ecba880"
   },
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19c8338d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19c8338d",
    "outputId": "5afa028f-da33-4143-f22a-f705b87ab4df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.65746288 0.63714509 0.65033872 0.64226159 0.63861386]\n",
      "Mean cross-validation score: 0.645164428974944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Train the K-NN classifier\n",
    "k = 5\n",
    "# Create a StratifiedKFold object\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(nb_clf, X, y, cv=kf)\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Mean cross-validation score:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f82f2fd7",
   "metadata": {
    "id": "f82f2fd7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fe72311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fe72311",
    "outputId": "d838ecc9-22af-433b-b50e-09d0af8cca7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.52%\n",
      "Precision: 95.04%\n",
      "Recall: 30.63%\n",
      "F1 score: 46.31%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Create lists to store the evaluation metric values for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "for train_index, test_index in skf.split(X_numpy, y):\n",
    "    X_train, X_test = X_numpy[train_index], X_numpy[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the logistic regression model\n",
    "    nb_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = nb_clf.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Append evaluation metric values to the respective lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate the mean of the evaluation metric values across all folds\n",
    "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy: {:.2f}%\".format(mean_accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(mean_precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(mean_recall * 100))\n",
    "print(\"F1 score: {:.2f}%\".format(mean_f1 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc37ec",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99de42cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99de42cc",
    "outputId": "af3fd4a9-9368-4648-dcaa-1d95e75b6b53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1. 1. 1. 1. 1.]\n",
      "Mean cross-validation score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the Gradient Boosting classifier\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the Gradient Boosting classifier\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Train the K-NN classifier\n",
    "k = 5\n",
    "# Create a StratifiedKFold object\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(gb_clf, X, y, cv=kf)\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Mean cross-validation score:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23188887",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23188887",
    "outputId": "8c52e9dc-6d8b-4b24-e74a-dcc266384a91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n",
      "Precision: 100.00%\n",
      "Recall: 100.00%\n",
      "F1 score: 100.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Create lists to store the evaluation metric values for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "for train_index, test_index in skf.split(X_numpy, y):\n",
    "    X_train, X_test = X_numpy[train_index], X_numpy[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the logistic regression model\n",
    "    gb_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = gb_clf.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Append evaluation metric values to the respective lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate the mean of the evaluation metric values across all folds\n",
    "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy: {:.2f}%\".format(mean_accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(mean_precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(mean_recall * 100))\n",
    "print(\"F1 score: {:.2f}%\".format(mean_f1 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce3e287",
   "metadata": {},
   "source": [
    "## MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d732b4b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d732b4b2",
    "outputId": "e9d50542-861a-4729-f095-e6610cbec81f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.9713467  0.97551446 0.97498697 0.93955185 0.96143825]\n",
      "Mean cross-validation score: 0.9645676466304449\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Initialize the Neural Network classifier\n",
    "nn_clf = MLPClassifier(random_state=42)\n",
    "\n",
    "# Train the Neural Network classifier\n",
    "nn_clf.fit(X_train, y_train)\n",
    "\n",
    "# Train the K-NN classifier\n",
    "k = 5\n",
    "# Create a StratifiedKFold object\n",
    "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(nn_clf, X, y, cv=kf)\n",
    "\n",
    "print('Cross-validation scores:', scores)\n",
    "print('Mean cross-validation score:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f072b3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f072b3d",
    "outputId": "dd95b745-3110-4b96-836f-da04c9a28e9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.46%\n",
      "Precision: 98.33%\n",
      "Recall: 94.54%\n",
      "F1 score: 96.36%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "# Create a StratifiedKFold object\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Create lists to store the evaluation metric values for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "for train_index, test_index in skf.split(X_numpy, y):\n",
    "    X_train, X_test = X_numpy[train_index], X_numpy[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train the logistic regression model\n",
    "    nn_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = nn_clf.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Append evaluation metric values to the respective lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate the mean of the evaluation metric values across all folds\n",
    "mean_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
    "mean_precision = sum(precision_scores) / len(precision_scores)\n",
    "mean_recall = sum(recall_scores) / len(recall_scores)\n",
    "mean_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy: {:.2f}%\".format(mean_accuracy * 100))\n",
    "print(\"Precision: {:.2f}%\".format(mean_precision * 100))\n",
    "print(\"Recall: {:.2f}%\".format(mean_recall * 100))\n",
    "print(\"F1 score: {:.2f}%\".format(mean_f1 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbfd0109",
   "metadata": {
    "id": "cbfd0109"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
